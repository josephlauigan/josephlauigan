{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from scipy.stats import beta\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe problem formuation is such that, at each tim t, we are to recommend one category A_i to the user and observe the\\nreward for that category (r_i,t). We want to maximize the reward (the total number of clicks through all rounds), and such this\\nis a multi-bandit problem. As we are only allowed to present the user one category during each round, this is not a semi-bandit problem,\\nas we are not presenting the user with multiple categories in each round and building statistics on sets of categories. We are to build\\nthe statistics of each category individually, and in an online fashion.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The problem formuation is such that, at each tim t, we are to recommend one category A_i to the user and observe the\n",
    "reward for that category (r_i,t). We want to maximize the reward (the total number of clicks through all rounds), and such this\n",
    "is a multi-bandit problem. As we are only allowed to present the user one category during each round, this is not a semi-bandit problem,\n",
    "as we are not presenting the user with multiple categories in each round and building statistics on sets of categories. We are to build\n",
    "the statistics of each category individually, and in an online fashion.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import ad data\n",
    "yahoo_data = pd.read_csv(\"yahoo_ad_clicks.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_len = yahoo_data.shape[0]\n",
    "rounds = yahoo_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTwo approached to the multi-bandit problem with partial feedback will be explored: \\n- Implementation of the standard Benoulli Bandits approach for partial feedback\\n- EXP3 algorithm, as the update has an indicator function that only updates loss vector based on chosen index at each round\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Two approached to the multi-bandit problem with partial feedback will be explored: \n",
    "- Implementation of the standard Benoulli Bandits approach for partial feedback\n",
    "- EXP3 algorithm, as the update has an indicator function that only updates loss vector based on chosen index at each round\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 0\n",
      "its been  0.0638858437538147 minutes\n",
      "t: 1\n",
      "its been  0.12825833956400554 minutes\n",
      "t: 2\n",
      "its been  0.1870082934697469 minutes\n",
      "t: 3\n",
      "its been  0.2436279296875 minutes\n",
      "t: 4\n",
      "its been  0.3012129227320353 minutes\n",
      "t: 5\n",
      "its been  0.36066593329111735 minutes\n",
      "t: 6\n",
      "its been  0.4212447802225749 minutes\n",
      "t: 7\n",
      "its been  0.48692257404327394 minutes\n",
      "t: 8\n",
      "its been  0.5517752329508464 minutes\n",
      "t: 9\n",
      "its been  0.6163130164146423 minutes\n",
      "t: 10\n",
      "its been  0.6805862426757813 minutes\n",
      "t: 11\n",
      "its been  0.743826150894165 minutes\n",
      "t: 12\n",
      "its been  0.8070074955622355 minutes\n",
      "t: 13\n",
      "its been  0.8690991640090943 minutes\n",
      "t: 14\n",
      "its been  0.932883886496226 minutes\n",
      "t: 15\n",
      "its been  0.9958765745162964 minutes\n",
      "t: 16\n",
      "its been  1.0592479745546977 minutes\n",
      "t: 17\n",
      "its been  1.1215372522672018 minutes\n",
      "t: 18\n",
      "its been  1.1847696026166281 minutes\n",
      "t: 19\n",
      "its been  1.2475871960322062 minutes\n",
      "t: 20\n",
      "its been  1.310852587223053 minutes\n",
      "t: 21\n",
      "its been  1.373786747455597 minutes\n",
      "t: 22\n",
      "its been  1.4371919234593709 minutes\n",
      "t: 23\n",
      "its been  1.4986869017283122 minutes\n",
      "t: 24\n",
      "its been  1.5618366320927939 minutes\n",
      "t: 25\n",
      "its been  1.6243242104848226 minutes\n",
      "t: 26\n",
      "its been  1.6868284662564597 minutes\n",
      "t: 27\n",
      "its been  1.7504489183425904 minutes\n",
      "t: 28\n",
      "its been  1.8133082230885824 minutes\n",
      "t: 29\n",
      "its been  1.8752441128094992 minutes\n",
      "t: 30\n",
      "its been  1.9386321385701497 minutes\n",
      "t: 31\n",
      "its been  2.0015090823173525 minutes\n",
      "t: 32\n",
      "its been  2.0641041954358417 minutes\n",
      "t: 33\n",
      "its been  2.127905495961507 minutes\n",
      "t: 34\n",
      "its been  2.191087547938029 minutes\n",
      "t: 35\n",
      "its been  2.252707918485006 minutes\n",
      "t: 36\n",
      "its been  2.3165257811546325 minutes\n",
      "t: 37\n",
      "its been  2.3800385077794393 minutes\n",
      "t: 38\n",
      "its been  2.4430965542793275 minutes\n",
      "t: 39\n",
      "its been  2.5083046555519104 minutes\n",
      "t: 40\n",
      "its been  2.5719985206921896 minutes\n",
      "t: 41\n",
      "its been  2.6361643115679425 minutes\n",
      "t: 42\n",
      "its been  2.7000903566678365 minutes\n",
      "t: 43\n",
      "its been  2.763694707552592 minutes\n",
      "t: 44\n",
      "its been  2.8263559977213544 minutes\n",
      "t: 45\n",
      "its been  2.889958914120992 minutes\n",
      "t: 46\n",
      "its been  2.952909521261851 minutes\n",
      "t: 47\n",
      "its been  3.0161080797513327 minutes\n",
      "t: 48\n",
      "its been  3.078694935639699 minutes\n",
      "t: 49\n",
      "its been  3.1424060742060345 minutes\n",
      "t: 50\n",
      "its been  3.205919607480367 minutes\n",
      "t: 51\n",
      "its been  3.268770186106364 minutes\n",
      "t: 52\n",
      "its been  3.331952206293742 minutes\n",
      "t: 53\n",
      "its been  3.3955482800801593 minutes\n",
      "t: 54\n",
      "its been  3.4579615672429402 minutes\n",
      "t: 55\n",
      "its been  3.5211015661557514 minutes\n",
      "t: 56\n",
      "its been  3.5848622798919676 minutes\n",
      "t: 57\n",
      "its been  3.64786323706309 minutes\n",
      "t: 58\n",
      "its been  3.7161202510197957 minutes\n",
      "t: 59\n",
      "its been  3.77964194615682 minutes\n",
      "t: 60\n",
      "its been  3.842285958925883 minutes\n",
      "t: 61\n",
      "its been  3.904989278316498 minutes\n",
      "t: 62\n",
      "its been  3.9676756064097085 minutes\n",
      "t: 63\n",
      "its been  4.030244914690654 minutes\n",
      "t: 64\n",
      "its been  4.0936171015103655 minutes\n",
      "t: 65\n",
      "its been  4.158172070980072 minutes\n",
      "t: 66\n",
      "its been  4.221708973248799 minutes\n",
      "t: 67\n",
      "its been  4.284370974699656 minutes\n",
      "t: 68\n",
      "its been  4.3482962369918825 minutes\n",
      "t: 69\n",
      "its been  4.414264198144277 minutes\n",
      "t: 70\n",
      "its been  4.488969953854879 minutes\n",
      "t: 71\n",
      "its been  4.553648980458577 minutes\n",
      "t: 72\n",
      "its been  4.616822024186452 minutes\n",
      "t: 73\n",
      "its been  4.680351984500885 minutes\n",
      "t: 74\n",
      "its been  4.744616289933522 minutes\n",
      "t: 75\n",
      "its been  4.807533776760101 minutes\n",
      "t: 76\n",
      "its been  4.8707406401634215 minutes\n",
      "t: 77\n",
      "its been  4.937205235163371 minutes\n",
      "t: 78\n",
      "its been  5.000337000687917 minutes\n",
      "t: 79\n",
      "its been  5.063940652211508 minutes\n",
      "t: 80\n",
      "its been  5.12664395570755 minutes\n",
      "t: 81\n",
      "its been  5.188725852966309 minutes\n",
      "t: 82\n",
      "its been  5.251940957705179 minutes\n",
      "t: 83\n",
      "its been  5.315759547551473 minutes\n",
      "t: 84\n",
      "its been  5.379015978177389 minutes\n",
      "t: 85\n",
      "its been  5.442495628197988 minutes\n",
      "t: 86\n",
      "its been  5.505909876028697 minutes\n",
      "t: 87\n",
      "its been  5.56893413066864 minutes\n",
      "t: 88\n",
      "its been  5.632182323932648 minutes\n",
      "t: 89\n",
      "its been  5.6955635031064356 minutes\n",
      "t: 90\n",
      "its been  5.75868787765503 minutes\n",
      "t: 91\n",
      "its been  5.8219020764033 minutes\n",
      "t: 92\n",
      "its been  5.885902523994446 minutes\n",
      "t: 93\n",
      "its been  5.94822568098704 minutes\n",
      "t: 94\n",
      "its been  6.010358083248138 minutes\n",
      "t: 95\n",
      "its been  6.073720951875051 minutes\n",
      "t: 96\n",
      "its been  6.136556514104208 minutes\n",
      "t: 97\n",
      "its been  6.200126393636068 minutes\n",
      "t: 98\n",
      "its been  6.263482069969177 minutes\n",
      "t: 99\n",
      "its been  6.325945623715719 minutes\n",
      "EXP3 in partial feedback got avg  11107.959999999997 successful rounds out of  32657\n",
      "Avg. Regret over  100 trials is: 1262.6000000000006\n"
     ]
    }
   ],
   "source": [
    "#Now, will explore EXP3 in a partial feedback setting. Instead of reward, loss = 1 if r_i,t = 0.\n",
    "eta = 1/np.sqrt(rounds)\n",
    "data = np.array(yahoo_data)\n",
    "exp3_avg_regret = 0\n",
    "exp3_avg_success = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for t in range(repeats):\n",
    "    print('t:',t)\n",
    "    running_loss = 0\n",
    "    prob = 1/categories_len * np.ones(categories_len)\n",
    "    exp3_success = 0\n",
    "    exp3_fails = 0\n",
    "    exp3_best_loss = 0\n",
    "    exp3_loss = np.zeros(categories_len)\n",
    "    for i in range(rounds):\n",
    "        loss_update = np.zeros(categories_len)\n",
    "        chosen_idx = np.random.choice(range(categories_len), p=prob)\n",
    "        exp3_best_idx = np.argmax(prob)\n",
    "        exp3_best_loss += (1-data[exp3_best_idx][i])\n",
    "    \n",
    "        if data[chosen_idx][i] == 1:\n",
    "            loss = 0\n",
    "            exp3_success += 1\n",
    "        else:\n",
    "            loss = 1\n",
    "            exp3_fails += 1\n",
    "        \n",
    "        running_loss += loss\n",
    "        loss_update[chosen_idx] = loss/prob[chosen_idx]\n",
    "        exp3_loss += loss_update\n",
    "    \n",
    "        prob = [np.exp(-eta*exp3_loss[r]) for r in range(categories_len)]\n",
    "        prob = prob/sum(prob)\n",
    "        \n",
    "    exp3_avg_regret += (1/repeats)*(running_loss - exp3_best_loss)\n",
    "    exp3_avg_success += (1/repeats)*(exp3_success)\n",
    "    print('its been ',(time.time() - start)/60, 'minutes')\n",
    "\n",
    "print('EXP3 in partial feedback got avg ',exp3_avg_success,'successful rounds out of ',rounds)\n",
    "print('Avg. Regret over ',repeats,'trials is:',exp3_avg_regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 0\n",
      "its been  0.4795909285545349 minutes\n",
      "t: 1\n",
      "its been  0.930222753683726 minutes\n",
      "t: 2\n",
      "its been  1.12736519575119 minutes\n",
      "t: 3\n",
      "its been  1.484958299001058 minutes\n",
      "t: 4\n",
      "its been  1.7083481947580974 minutes\n",
      "t: 5\n",
      "its been  1.9300350507100423 minutes\n",
      "t: 6\n",
      "its been  2.1505308707555133 minutes\n",
      "t: 7\n",
      "its been  2.37011874516805 minutes\n",
      "t: 8\n",
      "its been  2.586398545900981 minutes\n",
      "t: 9\n",
      "its been  2.806879250208537 minutes\n",
      "t: 10\n",
      "its been  3.0246553500493367 minutes\n",
      "t: 11\n",
      "its been  3.2411680221557617 minutes\n",
      "t: 12\n",
      "its been  3.460233716169993 minutes\n",
      "t: 13\n",
      "its been  3.677102224032084 minutes\n",
      "t: 14\n",
      "its been  3.897201605637868 minutes\n",
      "t: 15\n",
      "its been  4.117044321695963 minutes\n",
      "t: 16\n",
      "its been  4.335647793610891 minutes\n",
      "t: 17\n",
      "its been  4.553441115220388 minutes\n",
      "t: 18\n",
      "its been  4.780601191520691 minutes\n",
      "t: 19\n",
      "its been  5.0006341179211935 minutes\n",
      "t: 20\n",
      "its been  5.21775856812795 minutes\n",
      "t: 21\n",
      "its been  5.439825721581777 minutes\n",
      "t: 22\n",
      "its been  5.6651916146278385 minutes\n",
      "t: 23\n",
      "its been  5.882728334267934 minutes\n",
      "t: 24\n",
      "its been  6.108846306800842 minutes\n",
      "t: 25\n",
      "its been  6.328812972704569 minutes\n",
      "t: 26\n",
      "its been  6.550054228305816 minutes\n",
      "t: 27\n",
      "its been  6.772302536169688 minutes\n",
      "t: 28\n",
      "its been  6.997032276789347 minutes\n",
      "t: 29\n",
      "its been  7.2142555276552836 minutes\n",
      "t: 30\n",
      "its been  7.433331084251404 minutes\n",
      "t: 31\n",
      "its been  7.653951466083527 minutes\n",
      "t: 32\n",
      "its been  7.875167568524678 minutes\n",
      "t: 33\n",
      "its been  8.09725342988968 minutes\n",
      "t: 34\n",
      "its been  8.314137395222982 minutes\n",
      "t: 35\n",
      "its been  8.534460643927256 minutes\n",
      "t: 36\n",
      "its been  8.75608107248942 minutes\n",
      "t: 37\n",
      "its been  8.97757029136022 minutes\n",
      "t: 38\n",
      "its been  9.198289998372395 minutes\n",
      "t: 39\n",
      "its been  9.419315632184347 minutes\n",
      "t: 40\n",
      "its been  9.642233574390412 minutes\n",
      "t: 41\n",
      "its been  9.966592903931936 minutes\n",
      "t: 42\n",
      "its been  10.27430214881897 minutes\n",
      "t: 43\n",
      "its been  10.537355335553487 minutes\n",
      "t: 44\n",
      "its been  10.811857918898264 minutes\n",
      "t: 45\n",
      "its been  11.075365841388702 minutes\n",
      "t: 46\n",
      "its been  11.359780116875966 minutes\n",
      "t: 47\n",
      "its been  11.610392741362254 minutes\n",
      "t: 48\n",
      "its been  11.85329951842626 minutes\n",
      "t: 49\n",
      "its been  12.107540520032247 minutes\n",
      "t: 50\n",
      "its been  12.381465077400208 minutes\n",
      "t: 51\n",
      "its been  12.666673334439595 minutes\n",
      "t: 52\n",
      "its been  12.919624280929565 minutes\n",
      "t: 53\n",
      "its been  13.173253667354583 minutes\n",
      "t: 54\n",
      "its been  13.411176292101542 minutes\n",
      "t: 55\n",
      "its been  13.661531897385915 minutes\n",
      "t: 56\n",
      "its been  13.907704718907674 minutes\n",
      "t: 57\n",
      "its been  14.146858402093251 minutes\n",
      "t: 58\n",
      "its been  14.384756882985434 minutes\n",
      "t: 59\n",
      "its been  14.688217695554098 minutes\n",
      "t: 60\n",
      "its been  14.976806620756784 minutes\n",
      "t: 61\n",
      "its been  15.237834521134694 minutes\n",
      "t: 62\n",
      "its been  15.469349801540375 minutes\n",
      "t: 63\n",
      "its been  15.70112203359604 minutes\n",
      "t: 64\n",
      "its been  15.949700359503428 minutes\n",
      "t: 65\n",
      "its been  16.216474334398907 minutes\n",
      "t: 66\n",
      "its been  16.53482254743576 minutes\n",
      "t: 67\n",
      "its been  16.77751502195994 minutes\n",
      "t: 68\n",
      "its been  17.038362101713815 minutes\n",
      "t: 69\n",
      "its been  17.259982593854268 minutes\n",
      "t: 70\n",
      "its been  17.484885227680206 minutes\n",
      "t: 71\n",
      "its been  17.709382836023966 minutes\n",
      "t: 72\n",
      "its been  17.935442805290222 minutes\n",
      "t: 73\n",
      "its been  18.165321266651155 minutes\n",
      "t: 74\n",
      "its been  18.3861163576444 minutes\n",
      "t: 75\n",
      "its been  18.606843332449596 minutes\n",
      "t: 76\n",
      "its been  18.91710803906123 minutes\n",
      "t: 77\n",
      "its been  19.164901157220203 minutes\n",
      "t: 78\n",
      "its been  19.38692710399628 minutes\n",
      "t: 79\n",
      "its been  19.60941514571508 minutes\n",
      "t: 80\n",
      "its been  19.8275731643041 minutes\n",
      "t: 81\n",
      "its been  20.05664124091466 minutes\n",
      "t: 82\n",
      "its been  20.28472751379013 minutes\n",
      "t: 83\n",
      "its been  20.512067850430807 minutes\n",
      "t: 84\n",
      "its been  20.738499792416892 minutes\n",
      "t: 85\n",
      "its been  20.951407559712727 minutes\n",
      "t: 86\n",
      "its been  21.182518458366395 minutes\n",
      "t: 87\n",
      "its been  21.40423091650009 minutes\n",
      "t: 88\n",
      "its been  21.632459807395936 minutes\n",
      "t: 89\n",
      "its been  21.845838618278503 minutes\n",
      "t: 90\n",
      "its been  22.066599694887795 minutes\n",
      "t: 91\n",
      "its been  22.283946665128074 minutes\n",
      "t: 92\n",
      "its been  22.509370052814482 minutes\n",
      "t: 93\n",
      "its been  22.745432670911153 minutes\n",
      "t: 94\n",
      "its been  22.970070807139077 minutes\n",
      "t: 95\n",
      "its been  23.19088139136632 minutes\n",
      "t: 96\n",
      "its been  23.413783884048463 minutes\n",
      "t: 97\n",
      "its been  23.636155883471172 minutes\n",
      "t: 98\n",
      "its been  23.84975873231888 minutes\n",
      "t: 99\n",
      "its been  24.07503343820572 minutes\n",
      "EXP3++ in partial feedback got avg  6454.399999999997 successful rounds out of  32657\n",
      "Avg. Regret over  100 trials is: 1262.6000000000006\n"
     ]
    }
   ],
   "source": [
    "#Now, will explore EXP3++, set parameters eta = 1/sqrt(rounds),upsilon = 0, upsilon update += e[chosen_idx]\n",
    "eta = 1/np.sqrt(rounds)\n",
    "data = np.array(yahoo_data)\n",
    "exp3p_avg_regret = 0\n",
    "exp3p_avg_success = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for t in range(repeats):\n",
    "    print('t:',t)\n",
    "    exp3p_success = 0\n",
    "    exp3p_fails = 0\n",
    "    exp3p_regret = 0\n",
    "    exp3p_loss = np.zeros(categories_len)\n",
    "    exp3p_best_loss = 0\n",
    "    upsilon = np.zeros(categories_len)\n",
    "    n = np.ones(categories_len)\n",
    "    running_loss = 0\n",
    "    prob = 1/categories_len * np.ones(categories_len)\n",
    "    for i in range(rounds):\n",
    "        loss_update = np.zeros(categories_len)\n",
    "        beta = 0.5*np.sqrt(np.log(rounds)/((i+1)*rounds))\n",
    "    \n",
    "        e = [np.min([(1/(2*rounds)),beta,upsilon[r]]) for r in range(categories_len)]\n",
    "        prob = [np.exp(-eta*exp3_loss[r]) for r in range(categories_len)]\n",
    "        prob = prob/sum(prob)\n",
    "        const = (1-sum(e))\n",
    "        prob1 = [const*prob[r]+e[r] for r in range(categories_len)]\n",
    "    \n",
    "        chosen_idx = np.random.choice(range(categories_len), p=prob1)\n",
    "        best_idx = np.argmax(prob1)\n",
    "    \n",
    "        exp3p_best_loss += (1-data[best_idx][i])\n",
    "    \n",
    "    \n",
    "        if data[chosen_idx][i] == 1:\n",
    "            loss = 0\n",
    "            exp3p_success += 1\n",
    "            upsilon[chosen_idx] +=  beta #np.exp(-eta*i)\n",
    "        else:\n",
    "            loss = 1\n",
    "            exp3p_fails += 1\n",
    "        running_loss += loss\n",
    "        loss_update[chosen_idx] = loss/prob[chosen_idx]\n",
    "        exp3p_loss += loss_update\n",
    "        \n",
    "    exp3p_avg_regret += (1/repeats)*(running_loss - exp3p_best_loss)\n",
    "    exp3p_avg_success += (1/repeats)*exp3p_success\n",
    "    print('its been ',(time.time() - start)/60, 'minutes')\n",
    "    \n",
    "print('EXP3++ in partial feedback got avg ',exp3p_avg_success,'successful rounds out of ',rounds)\n",
    "print('Avg. Regret over ',repeats,'trials is:',exp3_avg_regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regret:  773\n"
     ]
    }
   ],
   "source": [
    "#Now, will explore EXP3++, set parameters upsilon = 0\n",
    "eta = 1/np.sqrt(rounds)\n",
    "data = np.array(yahoo_data)\n",
    "exp3p_success = 0\n",
    "exp3p_fails = 0\n",
    "exp3p_regret = 0\n",
    "exp3p_loss = np.zeros(categories_len)\n",
    "exp3p_best_loss = 0\n",
    "upsilon = np.zeros(categories_len)\n",
    "n = np.ones(categories_len)\n",
    "running_loss = 0\n",
    "prob = 1/categories_len * np.ones(categories_len)\n",
    "for i in range(rounds):\n",
    "    loss_update = np.zeros(categories_len)\n",
    "    beta = 0.5*np.sqrt(np.log(rounds)/((i+1)*rounds))\n",
    "    \n",
    "    e = [np.min([(1/(2*rounds)),beta,upsilon[r]]) for r in range(categories_len)]\n",
    "    prob = [np.exp(-eta*exp3_loss[r]) for r in range(categories_len)]\n",
    "    prob = prob/sum(prob)\n",
    "    const = (1-sum(e))\n",
    "    prob1 = [const*prob[r]+e[r] for r in range(categories_len)]\n",
    "    \n",
    "    chosen_idx = np.random.choice(range(categories_len), p=prob1)\n",
    "    best_idx = np.argmax(prob1)\n",
    "    \n",
    "    exp3p_best_loss += (1-data[best_idx][i])\n",
    "    \n",
    "    \n",
    "    if data[chosen_idx][i] == 1:\n",
    "        loss = 0\n",
    "        exp3p_success += 1\n",
    "        upsilon[chosen_idx] += e[chosen_idx]#beta \n",
    "    else:\n",
    "        loss = 1\n",
    "        exp3p_fails += 1\n",
    "    running_loss += loss\n",
    "    loss_update[chosen_idx] = loss/prob[chosen_idx]\n",
    "    exp3p_loss += loss_update\n",
    "        \n",
    "print('Regret: ',running_loss - exp3p_best_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 0\n",
      "its been  0.05419696569442749 minutes\n",
      "t: 1\n",
      "its been  0.10984797080357869 minutes\n",
      "t: 2\n",
      "its been  0.17074020703633627 minutes\n",
      "t: 3\n",
      "its been  0.22549784183502197 minutes\n",
      "t: 4\n",
      "its been  0.2794873674710592 minutes\n",
      "t: 5\n",
      "its been  0.33365876277287804 minutes\n",
      "t: 6\n",
      "its been  0.3916665593783061 minutes\n",
      "t: 7\n",
      "its been  0.4453082243601481 minutes\n",
      "t: 8\n",
      "its been  0.4994135061899821 minutes\n",
      "t: 9\n",
      "its been  0.5526755650838217 minutes\n",
      "t: 10\n",
      "its been  0.6064171115557353 minutes\n",
      "t: 11\n",
      "its been  0.6598196784655254 minutes\n",
      "t: 12\n",
      "its been  0.7135122934977214 minutes\n",
      "t: 13\n",
      "its been  0.7669233004252116 minutes\n",
      "t: 14\n",
      "its been  0.8199785908063253 minutes\n",
      "t: 15\n",
      "its been  0.8732234001159668 minutes\n",
      "t: 16\n",
      "its been  0.9266756057739258 minutes\n",
      "t: 17\n",
      "its been  0.9796070218086242 minutes\n",
      "t: 18\n",
      "its been  1.032489538192749 minutes\n",
      "t: 19\n",
      "its been  1.0855772614479064 minutes\n",
      "t: 20\n",
      "its been  1.1386830051740011 minutes\n",
      "t: 21\n",
      "its been  1.1912840445836386 minutes\n",
      "t: 22\n",
      "its been  1.2438100695610046 minutes\n",
      "t: 23\n",
      "its been  1.2970300634702048 minutes\n",
      "t: 24\n",
      "its been  1.3503169218699138 minutes\n",
      "t: 25\n",
      "its been  1.4032813906669617 minutes\n",
      "t: 26\n",
      "its been  1.4565351883570352 minutes\n",
      "t: 27\n",
      "its been  1.5099130153656006 minutes\n",
      "t: 28\n",
      "its been  1.5624234795570373 minutes\n",
      "t: 29\n",
      "its been  1.6158832708994548 minutes\n",
      "t: 30\n",
      "its been  1.6690957188606261 minutes\n",
      "t: 31\n",
      "its been  1.7223584969838461 minutes\n",
      "t: 32\n",
      "its been  1.7758017341295878 minutes\n",
      "t: 33\n",
      "its been  1.8289893746376038 minutes\n",
      "t: 34\n",
      "its been  1.8822018384933472 minutes\n",
      "t: 35\n",
      "its been  1.9382580637931823 minutes\n",
      "t: 36\n",
      "its been  1.991685434182485 minutes\n",
      "t: 37\n",
      "its been  2.0451218326886496 minutes\n",
      "t: 38\n",
      "its been  2.099375907580058 minutes\n",
      "t: 39\n",
      "its been  2.152959624926249 minutes\n",
      "t: 40\n",
      "its been  2.206329866250356 minutes\n",
      "t: 41\n",
      "its been  2.25955886443456 minutes\n",
      "t: 42\n",
      "its been  2.312729283173879 minutes\n",
      "t: 43\n",
      "its been  2.365595273176829 minutes\n",
      "t: 44\n",
      "its been  2.418385430177053 minutes\n",
      "t: 45\n",
      "its been  2.4702925086021423 minutes\n",
      "t: 46\n",
      "its been  2.5238431731859845 minutes\n",
      "t: 47\n",
      "its been  2.5768076101938884 minutes\n",
      "t: 48\n",
      "its been  2.6300372838974 minutes\n",
      "t: 49\n",
      "its been  2.6835060795148213 minutes\n",
      "t: 50\n",
      "its been  2.736907962958018 minutes\n",
      "t: 51\n",
      "its been  2.789129106203715 minutes\n",
      "t: 52\n",
      "its been  2.8423822045326235 minutes\n",
      "t: 53\n",
      "its been  2.8960252443949384 minutes\n",
      "t: 54\n",
      "its been  2.9491708715756735 minutes\n",
      "t: 55\n",
      "its been  3.0021280805269877 minutes\n",
      "t: 56\n",
      "its been  3.0551088134447735 minutes\n",
      "t: 57\n",
      "its been  3.1080394625663756 minutes\n",
      "t: 58\n",
      "its been  3.1613188068072002 minutes\n",
      "t: 59\n",
      "its been  3.2145222862561544 minutes\n",
      "t: 60\n",
      "its been  3.2675942301750185 minutes\n",
      "t: 61\n",
      "its been  3.32054283618927 minutes\n",
      "t: 62\n",
      "its been  3.3736313263575237 minutes\n",
      "t: 63\n",
      "its been  3.426834789911906 minutes\n",
      "t: 64\n",
      "its been  3.4801464557647703 minutes\n",
      "t: 65\n",
      "its been  3.5329538861910503 minutes\n",
      "t: 66\n",
      "its been  3.58558011452357 minutes\n",
      "t: 67\n",
      "its been  3.6386602958043417 minutes\n",
      "t: 68\n",
      "its been  3.691468099753062 minutes\n",
      "t: 69\n",
      "its been  3.74443146387736 minutes\n",
      "t: 70\n",
      "its been  3.797437246640523 minutes\n",
      "t: 71\n",
      "its been  3.850748908519745 minutes\n",
      "t: 72\n",
      "its been  3.9056973894437155 minutes\n",
      "t: 73\n",
      "its been  3.960373032093048 minutes\n",
      "t: 74\n",
      "its been  4.01366818745931 minutes\n",
      "t: 75\n",
      "its been  4.067244362831116 minutes\n",
      "t: 76\n",
      "its been  4.120845365524292 minutes\n",
      "t: 77\n",
      "its been  4.174066094557444 minutes\n",
      "t: 78\n",
      "its been  4.227163537343343 minutes\n",
      "t: 79\n",
      "its been  4.280185155073801 minutes\n",
      "t: 80\n",
      "its been  4.332629565397898 minutes\n",
      "t: 81\n",
      "its been  4.386031424999237 minutes\n",
      "t: 82\n",
      "its been  4.438880892594655 minutes\n",
      "t: 83\n",
      "its been  4.492216618855794 minutes\n",
      "t: 84\n",
      "its been  4.545106677214305 minutes\n",
      "t: 85\n",
      "its been  4.597964417934418 minutes\n",
      "t: 86\n",
      "its been  4.651035618782044 minutes\n",
      "t: 87\n",
      "its been  4.704290203253428 minutes\n",
      "t: 88\n",
      "its been  4.757519090175629 minutes\n",
      "t: 89\n",
      "its been  4.810656476020813 minutes\n",
      "t: 90\n",
      "its been  4.885511084397634 minutes\n",
      "t: 91\n",
      "its been  4.951826790968577 minutes\n",
      "t: 92\n",
      "its been  5.0067334016164144 minutes\n",
      "t: 93\n",
      "its been  5.060251621405284 minutes\n",
      "t: 94\n",
      "its been  5.115531480312347 minutes\n",
      "t: 95\n",
      "its been  5.169206142425537 minutes\n",
      "t: 96\n",
      "its been  5.2224516789118445 minutes\n",
      "t: 97\n",
      "its been  5.275531880060831 minutes\n",
      "t: 98\n",
      "its been  5.329075006643931 minutes\n",
      "t: 99\n",
      "its been  5.3825858473777775 minutes\n",
      "Mult. Weight Update in full feedback got avg  10392.09 successful rounds out of  32657\n",
      "Avg. Regret over  100 trials is: 675.9100000000004\n"
     ]
    }
   ],
   "source": [
    "#Now, will explore Mult. Weight Update  in a full feedback setting. Instead of reward, loss = 1 if r_i,t = 0.\n",
    "eta = 1/np.sqrt(rounds)\n",
    "data = np.array(yahoo_data)\n",
    "mw_avg_regret = 0\n",
    "mw_avg_success = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for t in range(repeats):\n",
    "    print('t:',t)\n",
    "    mw_success = 0\n",
    "    mw_fails = 0\n",
    "    mw_best_loss = 0\n",
    "    mw_loss = np.zeros(categories_len)\n",
    "    running_loss = 0\n",
    "    prob = 1/categories_len * np.ones(categories_len)\n",
    "    for i in range(rounds):\n",
    "        #loss_update = np.zeros(categories_len)\n",
    "        chosen_idx = np.random.choice(range(categories_len), p=prob)\n",
    "        mw_best_idx = np.argmax(prob)\n",
    "        mw_best_loss += (1-data[mw_best_idx][i])\n",
    "    \n",
    "        if data[chosen_idx][i] == 1:\n",
    "            loss = 0\n",
    "            mw_success += 1\n",
    "        else:\n",
    "            loss = 1\n",
    "            mw_fails += 1\n",
    "        running_loss += loss\n",
    "        #loss_update[chosen_idx] = loss/prob[chosen_idx]\n",
    "        loss_update = [(1-data[r][i]) for r in range(categories_len)]\n",
    "    \n",
    "        prob = [prob[r]*(1-eta*loss_update[r]) for r in range(categories_len)]\n",
    "        prob = prob/sum(prob)\n",
    "        \n",
    "    mw_avg_regret += (1/repeats)*(running_loss - mw_best_loss)\n",
    "    mw_avg_success += (1/repeats)*(mw_success)\n",
    "    print('its been ',(time.time() - start)/60, 'minutes')\n",
    "      \n",
    "\n",
    "print('Mult. Weight Update in full feedback got avg ',mw_avg_success,'successful rounds out of ',rounds)\n",
    "print('Avg. Regret over ',repeats,'trials is:',mw_avg_regret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 0\n",
      "its been  0.8593113382657369 minutes\n",
      "t: 1\n",
      "its been  1.8100257078806559 minutes\n",
      "t: 2\n",
      "its been  2.664162111282349 minutes\n",
      "t: 3\n",
      "its been  3.5173388520876565 minutes\n",
      "t: 4\n",
      "its been  4.37382157643636 minutes\n",
      "t: 5\n",
      "its been  5.23793592453003 minutes\n",
      "t: 6\n",
      "its been  6.110952663421631 minutes\n",
      "t: 7\n",
      "its been  6.964980943997701 minutes\n",
      "t: 8\n",
      "its been  7.819993619124094 minutes\n",
      "t: 9\n",
      "its been  8.676634120941163 minutes\n",
      "t: 10\n",
      "its been  9.57787319024404 minutes\n",
      "t: 11\n",
      "its been  10.433504474163055 minutes\n",
      "t: 12\n",
      "its been  11.38197155793508 minutes\n",
      "t: 13\n",
      "its been  12.325536064306895 minutes\n",
      "t: 14\n",
      "its been  13.184035845597585 minutes\n",
      "t: 15\n",
      "its been  14.259842443466187 minutes\n",
      "t: 16\n",
      "its been  15.189816665649413 minutes\n",
      "t: 17\n",
      "its been  16.042166034380596 minutes\n",
      "t: 18\n",
      "its been  16.98179635206858 minutes\n",
      "t: 19\n",
      "its been  17.90581834713618 minutes\n",
      "t: 20\n",
      "its been  18.817093034585316 minutes\n",
      "t: 21\n",
      "its been  19.74164422750473 minutes\n",
      "t: 22\n",
      "its been  20.665584993362426 minutes\n",
      "t: 23\n",
      "its been  21.515628695487976 minutes\n",
      "t: 24\n",
      "its been  22.519490905602773 minutes\n",
      "t: 25\n",
      "its been  23.486152176062266 minutes\n",
      "t: 26\n",
      "its been  24.376942280928294 minutes\n",
      "t: 27\n",
      "its been  25.224959925810495 minutes\n",
      "t: 28\n",
      "its been  26.06438170671463 minutes\n",
      "t: 29\n",
      "its been  26.913656572500866 minutes\n",
      "t: 30\n",
      "its been  27.814018742243448 minutes\n",
      "t: 31\n",
      "its been  28.649738303820293 minutes\n",
      "t: 32\n",
      "its been  29.485678120454153 minutes\n",
      "t: 33\n",
      "its been  30.326645044485726 minutes\n",
      "t: 34\n",
      "its been  31.18132631381353 minutes\n",
      "t: 35\n",
      "its been  32.03045245409012 minutes\n",
      "t: 36\n",
      "its been  32.905792796611784 minutes\n",
      "t: 37\n",
      "its been  33.75157915353775 minutes\n",
      "t: 38\n",
      "its been  34.578972256183626 minutes\n",
      "t: 39\n",
      "its been  35.43532338142395 minutes\n",
      "t: 40\n",
      "its been  36.336051285266876 minutes\n",
      "t: 41\n",
      "its been  37.18552350997925 minutes\n",
      "t: 42\n",
      "its been  38.00735381444295 minutes\n",
      "t: 43\n",
      "its been  38.85427273909251 minutes\n",
      "t: 44\n",
      "its been  39.677606868743894 minutes\n",
      "t: 45\n",
      "its been  40.51596191724141 minutes\n",
      "t: 46\n",
      "its been  41.40174293120702 minutes\n",
      "t: 47\n",
      "its been  42.25190166632334 minutes\n",
      "t: 48\n",
      "its been  43.09833282629649 minutes\n",
      "t: 49\n",
      "its been  43.95897440910339 minutes\n",
      "t: 50\n",
      "its been  44.806852249304455 minutes\n",
      "t: 51\n",
      "its been  45.646257503827414 minutes\n",
      "t: 52\n",
      "its been  46.488803315162656 minutes\n",
      "t: 53\n",
      "its been  47.33554032246272 minutes\n",
      "t: 54\n",
      "its been  48.17785404920578 minutes\n",
      "t: 55\n",
      "its been  49.014596684773764 minutes\n",
      "t: 56\n",
      "its been  49.85275371869405 minutes\n",
      "t: 57\n",
      "its been  50.68769416809082 minutes\n",
      "t: 58\n",
      "its been  51.532017370065056 minutes\n",
      "t: 59\n",
      "its been  52.37104919751485 minutes\n",
      "t: 60\n",
      "its been  53.21653797626495 minutes\n",
      "t: 61\n",
      "its been  54.06792985598246 minutes\n",
      "t: 62\n",
      "its been  54.91889117558797 minutes\n",
      "t: 63\n",
      "its been  55.74779702425003 minutes\n",
      "t: 64\n",
      "its been  56.583961013952894 minutes\n",
      "t: 65\n",
      "its been  57.43407016595204 minutes\n",
      "t: 66\n",
      "its been  58.26360530455907 minutes\n",
      "t: 67\n",
      "its been  59.106018531322476 minutes\n",
      "t: 68\n",
      "its been  59.95170506636302 minutes\n",
      "t: 69\n",
      "its been  60.794994882742564 minutes\n",
      "t: 70\n",
      "its been  61.63730998039246 minutes\n",
      "t: 71\n",
      "its been  62.473912211259204 minutes\n",
      "t: 72\n",
      "its been  63.30835664272308 minutes\n",
      "t: 73\n",
      "its been  64.14319726626078 minutes\n",
      "t: 74\n",
      "its been  64.98190815846125 minutes\n",
      "t: 75\n",
      "its been  65.86688595612844 minutes\n",
      "t: 76\n",
      "its been  66.70584495862325 minutes\n",
      "t: 77\n",
      "its been  67.54558756351472 minutes\n",
      "t: 78\n",
      "its been  68.38412507375081 minutes\n",
      "t: 79\n",
      "its been  69.23493001858394 minutes\n",
      "t: 80\n",
      "its been  70.07145774761835 minutes\n",
      "t: 81\n",
      "its been  70.909423883756 minutes\n",
      "t: 82\n",
      "its been  71.75822736422221 minutes\n",
      "t: 83\n",
      "its been  72.6036081592242 minutes\n",
      "t: 84\n",
      "its been  73.44927880764007 minutes\n",
      "t: 85\n",
      "its been  74.30554004907609 minutes\n",
      "t: 86\n",
      "its been  75.16680886745453 minutes\n",
      "t: 87\n",
      "its been  76.01694350639978 minutes\n",
      "t: 88\n",
      "its been  76.8573159535726 minutes\n",
      "t: 89\n",
      "its been  77.70998775959015 minutes\n",
      "t: 90\n",
      "its been  78.5562460343043 minutes\n",
      "t: 91\n",
      "its been  79.4171689748764 minutes\n",
      "t: 92\n",
      "its been  80.25770499308904 minutes\n",
      "t: 93\n",
      "its been  81.09267102877298 minutes\n",
      "t: 94\n",
      "its been  81.93184445699056 minutes\n",
      "t: 95\n",
      "its been  82.77831587791442 minutes\n",
      "t: 96\n",
      "its been  83.61886949141821 minutes\n",
      "t: 97\n",
      "its been  84.46184621651967 minutes\n",
      "t: 98\n",
      "its been  85.30711077054342 minutes\n",
      "t: 99\n",
      "its been  86.1879653374354 minutes\n",
      "Custom Update in partial feedback got avg 11547.749999999996 successful rounds out of  32657\n",
      "Avg. Regret over  100 trials is: 1.9599999999999964\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Basic idea: have k-experts, which will be their own EXP3 algorithms that hold their own prob. distributions. \n",
    "Each round t, each expert chooses an index to recommend. We will take a book out of EXP4 algorithm, which is contextual bandits.\n",
    "The k-expert recommendations will only be used to update their own distributions. The algorithm will sum the prob distributions\n",
    "over all the experts for each arm and multiply by the algorithms own prob. distribution over the arms. The algorithm will then\n",
    "sample this distribution to pick an arm to play that round and will incur a loss. That loss is wrapped up into a loss update\n",
    "vector and the algorithms probability distribution will be updated according to EXP3. Loss update vectors are calculated for \n",
    "each of the experts as well and their own prob distributions are updated as well. \n",
    "\"\"\"\n",
    "k = 10\n",
    "eta = 1/np.sqrt(rounds)\n",
    "cust_avg_regret = 0\n",
    "cust_avg_success = 0\n",
    "\n",
    "start = time.time()\n",
    "for t in range(repeats):\n",
    "    print('t:',t)\n",
    "    #each expert holds it's own prob dist over the arms, initialze to uniform dist.\n",
    "    k_prob_dist = [1/categories_len * np.ones(categories_len) for r in range(k)]\n",
    "\n",
    "    #algorithms prob distribution over arms\n",
    "    prob_dist = 1/categories_len * np.ones(categories_len)\n",
    "\n",
    "    loss_overall = np.zeros(categories_len)\n",
    "    exp_loss_overall = [np.zeros(categories_len) for r in range(k)]\n",
    "\n",
    "    cust_success = 0\n",
    "    cust_fails = 0\n",
    "    running_loss = 0\n",
    "    best_running_loss = 0\n",
    "    for i in range(rounds):\n",
    "        alg_loss_update = np.zeros(categories_len)\n",
    "        exp_loss_update = [np.zeros(categories_len) for r in range(k)]\n",
    "    \n",
    "        new_prob = [prob_dist[r]*sum(np.array(k_prob_dist)[:,r]) for r in range(categories_len)]\n",
    "        new_prob = new_prob/sum(new_prob)\n",
    "    \n",
    "        expert_chosen = list(map(lambda x: np.random.choice(range(categories_len), p=x),k_prob_dist))\n",
    "        chosen_idx = np.random.choice(range(categories_len),p=new_prob)\n",
    "        best_idx = np.argmax(new_prob)\n",
    "        best_running_loss += 1-data[best_idx][i]\n",
    "    \n",
    "        if data[chosen_idx][i] == 1:\n",
    "            loss = 0\n",
    "            cust_success += 1\n",
    "        else:\n",
    "            loss = 1\n",
    "            cust_fails += 1\n",
    "        \n",
    "        running_loss += loss\n",
    "    \n",
    "        #update algorithm\n",
    "        alg_loss_update[chosen_idx] = loss/prob[chosen_idx]\n",
    "        loss_overall += alg_loss_update\n",
    "        prob_dist = [np.exp(-eta*loss_overall[r]) for r in range(categories_len)]\n",
    "        prob_dist = prob/sum(prob_dist)\n",
    "    \n",
    "        #update experts\n",
    "        expert_loss = [1-data[r][i] for r in expert_chosen]\n",
    "        for a in range(k):\n",
    "            exp_loss_update[a][expert_chosen[a]] = expert_loss[a]/k_prob_dist[a][expert_chosen[a]]\n",
    "            exp_loss_overall[a] += exp_loss_update[a]\n",
    "            k_prob_dist[a] = [np.exp(-eta*exp_loss_overall[a][r]) for r in range(categories_len)]\n",
    "            k_prob_dist[a] = k_prob_dist[a]/sum(k_prob_dist[a])\n",
    "        \n",
    "    cust_avg_regret += (1/repeats)*(running_loss - best_running_loss)\n",
    "    cust_avg_success += (1/repeats)*(cust_success)\n",
    "    print('its been ',(time.time() - start)/60, 'minutes')\n",
    "        \n",
    "print('Custom Update in partial feedback got avg',cust_avg_success,'successful rounds out of ',rounds)\n",
    "print('Avg. Regret over ',repeats,'trials is:',cust_avg_regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Examine how size of K affects regret \n",
    "\"\"\"\n",
    "k_list = [5,10,15,20]\n",
    "k_regret = np.zeros(len(k_list))\n",
    "eta = 1/np.sqrt(rounds)\n",
    "cust_avg_regret = 0\n",
    "cust_avg_success = 0\n",
    "\n",
    "k_idx = 0\n",
    "for k in k_list:\n",
    "    \n",
    "    #each expert holds it's own prob dist over the arms, initialze to uniform dist.\n",
    "    k_prob_dist = [1/categories_len * np.ones(categories_len) for r in range(k)]\n",
    "\n",
    "    #algorithms prob distribution over arms\n",
    "    prob_dist = 1/categories_len * np.ones(categories_len)\n",
    "\n",
    "    loss_overall = np.zeros(categories_len)\n",
    "    exp_loss_overall = [np.zeros(categories_len) for r in range(k)]\n",
    "\n",
    "    cust_success = 0\n",
    "    cust_fails = 0\n",
    "    running_loss = 0\n",
    "    best_running_loss = 0\n",
    "    for i in range(rounds):\n",
    "        alg_loss_update = np.zeros(categories_len)\n",
    "        exp_loss_update = [np.zeros(categories_len) for r in range(k)]\n",
    "    \n",
    "        new_prob = [prob_dist[r]*sum(np.array(k_prob_dist)[:,r]) for r in range(categories_len)]\n",
    "        new_prob = new_prob/sum(new_prob)\n",
    "    \n",
    "        expert_chosen = list(map(lambda x: np.random.choice(range(categories_len), p=x),k_prob_dist))\n",
    "        chosen_idx = np.random.choice(range(categories_len),p=new_prob)\n",
    "        best_idx = np.argmax(new_prob)\n",
    "        best_running_loss += 1-data[best_idx][i]\n",
    "    \n",
    "        if data[chosen_idx][i] == 1:\n",
    "            loss = 0\n",
    "            cust_success += 1\n",
    "        else:\n",
    "            loss = 1\n",
    "            cust_fails += 1\n",
    "        \n",
    "        running_loss += loss\n",
    "    \n",
    "        #update algorithm\n",
    "        alg_loss_update[chosen_idx] = loss/prob[chosen_idx]\n",
    "        loss_overall += alg_loss_update\n",
    "        prob_dist = [np.exp(-eta*loss_overall[r]) for r in range(categories_len)]\n",
    "        prob_dist = prob/sum(prob_dist)\n",
    "    \n",
    "        #update experts\n",
    "        expert_loss = [1-data[r][i] for r in expert_chosen]\n",
    "        for a in range(k):\n",
    "            exp_loss_update[a][expert_chosen[a]] = expert_loss[a]/k_prob_dist[a][expert_chosen[a]]\n",
    "            exp_loss_overall[a] += exp_loss_update[a]\n",
    "            k_prob_dist[a] = [np.exp(-eta*exp_loss_overall[a][r]) for r in range(categories_len)]\n",
    "            k_prob_dist[a] = k_prob_dist[a]/sum(k_prob_dist[a])\n",
    "        \n",
    "    k_regret[k_idx] = running_loss - best_running_loss\n",
    "    k_idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Regret')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(k_list,k_regret)\n",
    "plt.xlabel('K_size')\n",
    "plt.ylabel('Regret')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unused/Lower Performance Algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 0\n",
      "its been  2.5092942357063293 minutes\n",
      "Thompson sampling got avg 1413.0 successful rounds out of  32657\n",
      "Avg. Regret over  1 trials is: -1168.0\n"
     ]
    }
   ],
   "source": [
    "# Thompson Sampling/Bernoulli Bandits\n",
    "\n",
    "data = np.array(yahoo_data)\n",
    "avg_regret_thm = 0\n",
    "avg_success_thm = 0\n",
    "\n",
    "start = time.time()\n",
    "for t in range(repeats):\n",
    "    print('t:',t)\n",
    "    success = np.zeros(categories_len)\n",
    "    fails = np.zeros(categories_len)\n",
    "    thm_best_reward = 0\n",
    "    for i in range(rounds):\n",
    "        S_t = success+1\n",
    "        F_t = fails+1\n",
    "        theta = beta_fcn(S_t,F_t)\n",
    "        theta = theta/sum(theta)\n",
    "        theta_max_idx = np.argmax(theta)\n",
    "    \n",
    "        chosen_idx = np.random.choice(range(categories_len), p=theta)\n",
    "    \n",
    "        if data[chosen_idx][i] == 1:\n",
    "            success[chosen_idx] += 1\n",
    "        else:\n",
    "            fails[chosen_idx] += 1\n",
    "        \n",
    "        thm_best_reward += data[theta_max_idx][i]\n",
    "\n",
    "    thm_success = sum(success)\n",
    "    \n",
    "    avg_regret_thm += (1/repeats)*(thm_best_reward - thm_success)\n",
    "    avg_success_thm += (1/repeats)*(thm_success)\n",
    "    print('its been ',(time.time()-start)/60,'minutes')\n",
    "\n",
    "print('Thompson sampling got avg',avg_success_thm,'successful rounds out of ',rounds)\n",
    "print('Avg. Regret over ',repeats,'trials is:',avg_regret_thm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_fcn(S,F):\n",
    "    x = np.linspace(0,1,num=categories_len)\n",
    "    gamma0 = [math.factorial(S[i]-1) for i in range(len(S))]\n",
    "    gamma1 = [math.factorial(F[i]-1) for i in range(len(F))]\n",
    "    gamma01 = [math.factorial((S[i]+F[i])- 1) for i in range(len(S))]\n",
    "\n",
    "    return [((gamma0[i]*gamma1[i])/gamma01[i])*(np.power(x[i],S[i]-1))*(np.power((1-x[i]),F[i]-1)) for i in range(len(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semi-bandit Update in partial feedback got  11424 successful rounds out of  32657\n",
      "Regret is: 1085\n"
     ]
    }
   ],
   "source": [
    "#semi bandit\n",
    "k = 10\n",
    "eta = 1/np.sqrt(rounds)\n",
    "\n",
    "sb_success = 0\n",
    "sb_fails = 0\n",
    "semi_band_success = np.zeros(k)\n",
    "semi_band_fails = np.zeros(k)\n",
    "semi_band_regret = np.zeros(k)\n",
    "data = np.array(yahoo_data)\n",
    "semi_band_k_loss = [np.zeros(categories_len) for r in range(k)]\n",
    "semi_band_best_loss = 0\n",
    "semi_band_running_loss = 0\n",
    "semi_band_k_running_loss = np.zeros(k)\n",
    "\n",
    "semi_band_prob = [1/categories_len * np.ones(categories_len) for r in range(k)]\n",
    "\n",
    "\"\"\"\n",
    "Idea is this: run k-diff MAB algorithms initially starting with unif. distr. each MAB_i will give a recommended\n",
    "x_i category to choose for round t. Observe loss_i for each MAB_i. For first round, choose a random MAB_i to be the x_i that\n",
    "incurs the running_loss_algo. After, the x_i recommendations from the other MAB_i are \"revealed\". Order the running_loss and \n",
    "update\n",
    "top element (if necesary). For subsequent rounds, the running_loss_algo will incure loss from x_i_best (x_i from MAB_i on the \n",
    "top of the stack). Then the running loss_i for the rest of the MAB_i are revealed. if the running_loss_i for top element is \n",
    "still\n",
    "better than the second element, keep using the top element. If not, reorder list to have a new top element to use for \n",
    "running_loss_algo\n",
    "in the subsequent rounds. \n",
    "\n",
    "Technically this is partial feedback since we are only getting feedback from k of the categories we can choose from.\n",
    "Uses submodulraity?\n",
    "\"\"\"\n",
    "start_k = np.random.choice(range(categories_len))\n",
    "sorted_list = []\n",
    "best_k = 0\n",
    "\n",
    "for i in range(rounds):\n",
    "    loss_update = [np.zeros(categories_len) for r in range(k)]\n",
    "    if not i: #first round\n",
    "        #for each of the k-elements, choose an index and find their loss\n",
    "        chosen_idx = list(map(lambda x: np.random.choice(range(categories_len), p=x),semi_band_prob))\n",
    "        semi_band_current_loss = list(map(lambda x: (1-data[x][i]),chosen_idx))\n",
    "        \n",
    "        #randomly choose one of the k to be the chosen element for the algorithm in this round\n",
    "        chosen_k = np.random.choice(k)\n",
    "        semi_band_running_loss += semi_band_current_loss[chosen_k]\n",
    "        \n",
    "        if not semi_band_current_loss[chosen_k]:\n",
    "            sb_success += 1\n",
    "        else:\n",
    "            sb_fails += 1\n",
    "        \n",
    "        #calculate running loss for rest of k elements\n",
    "        semi_band_k_running_loss = [semi_band_k_running_loss[r] + semi_band_k_running_loss[r] for r in range(k)]\n",
    "        best_k = np.argmin(semi_band_k_running_loss)\n",
    "        \n",
    "        best_k_best = np.argmax(semi_band_prob[best_k])\n",
    "        semi_band_best_loss += 1-data[best_k_best][i]\n",
    "        \n",
    "        #update the prob for each of the k \n",
    "        for r in range(k):\n",
    "            loss_update[r][chosen_idx[r]] = semi_band_current_loss[r]/semi_band_prob[r][chosen_idx[r]]\n",
    "            semi_band_k_loss[r] += loss_update[r]\n",
    "            semi_band_prob[r] = [np.exp(-eta*semi_band_k_loss[r][q]) for q in range(categories_len)]\n",
    "            semi_band_prob[r] = semi_band_prob[r]/sum(semi_band_prob[r])\n",
    "    else:\n",
    "        #for each of the k-elements, choose an index and find their loss\n",
    "        chosen_idx = list(map(lambda x: np.random.choice(range(categories_len), p=x),semi_band_prob))\n",
    "        semi_band_current_loss = list(map(lambda x: (1-data[x][i]),chosen_idx))\n",
    "        \n",
    "        semi_band_running_loss += semi_band_current_loss[best_k]\n",
    "        \n",
    "        if not semi_band_current_loss[best_k]:\n",
    "            sb_success += 1\n",
    "        else:\n",
    "            sb_fails += 1\n",
    "        \n",
    "        #calculate running loss for rest of k elements\n",
    "        semi_band_k_running_loss = [semi_band_k_running_loss[r] + semi_band_k_running_loss[r] for r in range(k)]\n",
    "        best_k = np.argmin(semi_band_k_running_loss)\n",
    "        \n",
    "        best_k_best = np.argmax(semi_band_prob[best_k])\n",
    "        semi_band_best_loss += 1-data[best_k_best][i]\n",
    "        \n",
    "        #update the prob for each of the k \n",
    "        for r in range(k):\n",
    "            loss_update[r][chosen_idx[r]] = semi_band_current_loss[r]/semi_band_prob[r][chosen_idx[r]]\n",
    "            semi_band_k_loss[r] += loss_update[r]\n",
    "            semi_band_prob[r] = [np.exp(-eta*semi_band_k_loss[r][q]) for q in range(categories_len)]\n",
    "            semi_band_prob[r] = semi_band_prob[r]/sum(semi_band_prob[r])\n",
    "        \n",
    "print('Semi-bandit Update in partial feedback got ',sb_success,'successful rounds out of ',rounds)\n",
    "print('Regret is:',(semi_band_running_loss - semi_band_best_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
